Project: Throw AI (Google's Gemini Text to Speech) generated audio through dialer or any other audio communication channel like MS Teams or other calling system.

1) First, use terminal commands to find out what microphone options available in my system and active microphone for capturing input audio from my system (laptop/desktop) and what are the different softwares (like teams or other calling systems) using what input audios

2) (think and answer the question) investigation question/Self-reflection technical question: lets suppose a dialer/softphone is running locally in my system and its capturing audio input from my system's microphone to capture my voice from microphone and transmits that voice to the other end person's mobile speaker. Now I want to throw/transmit a recorded audio through the same audio channel that the dialer/soft phone is using to pick up and transmit my input voice from there, so that the other end person can hear the recorded audio instead of my audio in their mobile phone while on call. Is that possible programmatically?

3) Write a test script/program which will send/throw/transmit a pre recorded test audio file (download.wav) through the same audio input channel that MS teams is using, so that the recorded audio gets heard by the person on the other side of the call. (In Vs Code terminal when I enter "Start", program will start transmitting)

4) Dynamic AI generated audio using google's gemini text to speech and sending/streaming that audio file through the same audio input channel that MS teams is using, so that the ai generated audio gets heard by the person on the other side of the call. 

The text message format, that needs to be converted into voice via google's gemini text to speech AI, is mentioned below:
"""This message is for {full_name}, this is Jessica with COUNTY Process Serving Division.
Your Case Number is {case_number}. Disclaimer: This message is generated by an AI system."""

So, there will be a GUI(a small resizable/responsive box over the screen) where I will write down the {full name} and {case number} and hit 'generate and send' button. Your program/code will generate audio using google's text to speech and the ai generated audio will be streamed through the **same audio input channel** that MS teams/local dialer/softphone is using, so that the ai generated audio gets heard by the person on the other side of the call. Its better if the generated audio gets streamed as being generated to minimize the latency instead of first the full audio generation and then send out through input channel, but if that's not possible then its okay. 

<--------------------------Google's Gemini TEXT to SPEECH generation Guide-------------------------------------------->

GEMINI_API_KEY - AIzaSyA2BTRMlCWbNjS1KmZ7upyQ4xY08Otu8mY

Google Gemini Single-speaker text-to-speech:
To convert text to single-speaker audio, set the response modality to "audio", and pass a SpeechConfig object with VoiceConfig set. You'll need to choose a voice name from the prebuilt output voices.
This example saves the output audio from the model in a wave file:

# To run this code you need to install the following dependencies:
# pip install google-genai

from google import genai
from google.genai import types
import wave

# Set up the wave file to save the output:
def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):
   with wave.open(filename, "wb") as wf:
      wf.setnchannels(channels)
      wf.setsampwidth(sample_width)
      wf.setframerate(rate)
      wf.writeframes(pcm)

client = genai.Client()

response = client.models.generate_content(
   model="gemini-2.5-flash-preview-tts",
   contents="Say cheerfully: Have a wonderful day!",
   config=types.GenerateContentConfig(
      response_modalities=["AUDIO"],
      speech_config=types.SpeechConfig(
         voice_config=types.VoiceConfig(
            prebuilt_voice_config=types.PrebuiltVoiceConfig(
               voice_name='Kore',
            )
         )
      ),
   )
)

data = response.candidates[0].content.parts[0].inline_data.data

file_name='out.wav'
wave_file(file_name, data) # Saves the file to current directory


-------------------------------------------------------------------------

Below is another example: 

# To run this code you need to install the following dependencies:
# pip install google-genai

import base64
import mimetypes
import os
import re
import struct
from google import genai
from google.genai import types


def save_binary_file(file_name, data):
    f = open(file_name, "wb")
    f.write(data)
    f.close()
    print(f"File saved to to: {file_name}")


def generate():
    client = genai.Client(
        api_key=os.environ.get("GEMINI_API_KEY"),
    )

    model = "gemini-2.5-flash-preview-tts"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text="""This message is for {full_name}, this is Jessica with COUNTY Process Serving Division.
Your Case Number is {case_number}. Disclaimer: This message is generated by an AI system."""),
            ],
        ),
    ]
    generate_content_config = types.GenerateContentConfig(
        temperature=1,
        response_modalities=[
            "audio",
        ],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                    voice_name="Kore"
                )
            )
        ),
    )

    file_index = 0
    for chunk in client.models.generate_content_stream(
        model=model,
        contents=contents,
        config=generate_content_config,
    ):
        if (
            chunk.candidates is None
            or chunk.candidates[0].content is None
            or chunk.candidates[0].content.parts is None
        ):
            continue
        if chunk.candidates[0].content.parts[0].inline_data and chunk.candidates[0].content.parts[0].inline_data.data:
            file_name = f"ENTER_FILE_NAME_{file_index}"
            file_index += 1
            inline_data = chunk.candidates[0].content.parts[0].inline_data
            data_buffer = inline_data.data
            file_extension = mimetypes.guess_extension(inline_data.mime_type)
            if file_extension is None:
                file_extension = ".wav"
                data_buffer = convert_to_wav(inline_data.data, inline_data.mime_type)
            save_binary_file(f"{file_name}{file_extension}", data_buffer)
        else:
            print(chunk.text)

def convert_to_wav(audio_data: bytes, mime_type: str) -> bytes:
    """Generates a WAV file header for the given audio data and parameters.

    Args:
        audio_data: The raw audio data as a bytes object.
        mime_type: Mime type of the audio data.

    Returns:
        A bytes object representing the WAV file header.
    """
    parameters = parse_audio_mime_type(mime_type)
    bits_per_sample = parameters["bits_per_sample"]
    sample_rate = parameters["rate"]
    num_channels = 1
    data_size = len(audio_data)
    bytes_per_sample = bits_per_sample // 8
    block_align = num_channels * bytes_per_sample
    byte_rate = sample_rate * block_align
    chunk_size = 36 + data_size  # 36 bytes for header fields before data chunk size

    # http://soundfile.sapp.org/doc/WaveFormat/

    header = struct.pack(
        "<4sI4s4sIHHIIHH4sI",
        b"RIFF",          # ChunkID
        chunk_size,       # ChunkSize (total file size - 8 bytes)
        b"WAVE",          # Format
        b"fmt ",          # Subchunk1ID
        16,               # Subchunk1Size (16 for PCM)
        1,                # AudioFormat (1 for PCM)
        num_channels,     # NumChannels
        sample_rate,      # SampleRate
        byte_rate,        # ByteRate
        block_align,      # BlockAlign
        bits_per_sample,  # BitsPerSample
        b"data",          # Subchunk2ID
        data_size         # Subchunk2Size (size of audio data)
    )
    return header + audio_data

def parse_audio_mime_type(mime_type: str) -> dict[str, int | None]:
    """Parses bits per sample and rate from an audio MIME type string.

    Assumes bits per sample is encoded like "L16" and rate as "rate=xxxxx".

    Args:
        mime_type: The audio MIME type string (e.g., "audio/L16;rate=24000").

    Returns:
        A dictionary with "bits_per_sample" and "rate" keys. Values will be
        integers if found, otherwise None.
    """
    bits_per_sample = 16
    rate = 24000

    # Extract rate from parameters
    parts = mime_type.split(";")
    for param in parts: # Skip the main type part
        param = param.strip()
        if param.lower().startswith("rate="):
            try:
                rate_str = param.split("=", 1)[1]
                rate = int(rate_str)
            except (ValueError, IndexError):
                # Handle cases like "rate=" with no value or non-integer value
                pass # Keep rate as default
        elif param.startswith("audio/L"):
            try:
                bits_per_sample = int(param.split("L", 1)[1])
            except (ValueError, IndexError):
                pass # Keep bits_per_sample as default if conversion fails

    return {"bits_per_sample": bits_per_sample, "rate": rate}


if __name__ == "__main__":
    generate()

  